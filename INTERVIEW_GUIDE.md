# 転職面接用 学習ガイド

このドキュメントは、転職活動の面接で「Unbundled DB Playground」について説明する際に、押さえるべき重要なポイントを体系的にまとめたものです。

---

## 🎯 このプロジェクトの本質（30秒で説明）

```
「DDIA 第12章の『解体されたデータベース』を実装しました。

PostgreSQLを元データとして、CDC経由でKafkaにイベントを配信し、
Elasticsearchで全文検索、Redisでキャッシュという
Polyglot Persistenceを実現しています。

特に重要なのは『導出関数』の概念で、
なぜそのデータストアを使うのかを理論的に説明できる点です。」
```

---

## 📚 押さえるべき5つの核心概念

### 1. 解体されたデータベース（Unbundled Database）

**定義**:

- 従来: 1つのデータベースが全機能を提供（インデックス、キャッシュ、検索）
- 解体後: 機能ごとに最適化されたデータストアを使い分ける

**なぜ解体するのか？**
| 理由 | 説明 |
|---|---|
| 専門化 | 各データストアがそれぞれの役割に特化 |
| スケーラビリティ | 部分的にスケール可能 |
| 技術選択の自由 | 用途に応じた最適なツールを選べる |

**面接での説明例**:

```
「モノリシックなデータベースでは、
全文検索もキャッシュも1つのDBで処理します。

しかし、解体されたデータベースでは、
- 全文検索 → Elasticsearch（転置インデックスに最適化）
- キャッシュ → Redis（インメモリで高速）
- トランザクション → PostgreSQL（ACID保証）

というように、機能ごとに専門化されたストアを使います。

御社のモノリス→マイクロサービス移行でも、
この考え方が境界設計に活きると考えています。」
```

---

### 2. 導出関数（Derived Data）

**定義**:

- 元データから変換・加工して生成されるデータ
- 元データ = Single Source of Truth

**具体例**:

```
PostgreSQL（元データ）
    ↓
導出関数1: 転置インデックス生成
    ↓
Elasticsearch（導出データ）

導出関数2: キャッシュ生成
    ↓
Redis（導出データ）
```

**重要な洞察**:

> 「なぜこのデータストアを使うのか？」を
> 導出関数の視点で説明できると、設計の意図が明確になる

**面接での説明例**:

```
「Elasticsearchを使う理由を導出関数で説明します。

PostgreSQLの投稿データから、
『全文検索』という導出関数を適用して、
転置インデックスというデータ構造を生成します。

この導出データをElasticsearchに保存することで、
PostgreSQLのLIKE検索より圧倒的に速い検索が可能になります。

つまり、『検索』という目的に最適化された
導出データを生成しているわけです。」
```

---

### 3. CDC (Change Data Capture)

**定義**:

- データベースの変更を自動的に検知し、イベントとして配信
- WAL (Write-Ahead Log) を監視

**仕組み**:

```
PostgreSQL
  ↓ WAL（トランザクションログ）
Debezium（CDC ツール）
  ↓ 変更イベント
Kafka
```

**なぜCDCが必要？**
| 従来の方法 | CDCの方法 |
|---|---|
| アプリがDB変更を検知 | DBが自動で通知 |
| 実装が複雑 | Debeziumが自動化 |
| 漏れのリスク | 確実に捕捉 |

**面接での説明例**:

```
「このプロジェクトでは、DebeziumというCDCツールを使っています。

PostgreSQLの変更を、アプリケーションコードを変更せずに
Kafkaに自動配信できます。

これにより、既存システムに影響を与えずに
新しいデータストア（Elasticsearch/Redis）を追加できます。

御社のレガシーシステムの段階的な刷新にも
この手法が使えると考えています。」
```

---

### 4. 結果整合性（Eventual Consistency）

**定義**:

- データの変更が、すぐには全システムに反映されない
- 時間が経てば最終的に整合する

**具体例（このプロジェクト）**:

```
[Time 0] PostgreSQLにINSERT
[Time 0] → クライアントに即座にレスポンス（強整合性）

[Time 1-2秒] Kafka経由で伝播
[Time 2-3秒] Elasticsearchに反映（結果整合性）
[Time 2-3秒] Redisに反映（結果整合性）
```

**トレードオフ**:
| 強整合性 | 結果整合性 |
|---|---|
| 即座に反映 | 遅延あり |
| 遅い | 速い |
| スケールしにくい | スケールしやすい |

**面接での説明例**:

```
「このプロジェクトの重要な学びは結果整合性の理解です。

PostgreSQLへの書き込みは即座に完了しますが、
Elasticsearchへの反映には数秒かかります。

統合テストでは、最大10秒待機して
伝播を確認する仕組みを実装しました。

これは、高スループットと整合性のトレードオフを
実際に体験できる設計です。

御社の分散システムでも、
どこを強整合性にして、どこを結果整合性にするかは
重要な設計判断だと理解しています。」
```

---

### 5. Polyglot Persistence

**定義**:

- 複数の異なるデータストアを使い分ける
- 「適材適所」のデータベース選択

**このプロジェクトの構成**:
| データストア | 役割 | 理由 |
|---|---|---|
| PostgreSQL | 元データ保存 | ACID保証、トランザクション |
| Elasticsearch | 全文検索 | 転置インデックス、ファジーマッチ |
| Redis | キャッシュ | インメモリ、高速アクセス |
| Kafka | イベントログ | 永続化、リプレイ可能 |

**面接での説明例**:

```
「このプロジェクトはPolyglot Persistenceの実践例です。

全てのデータを1つのデータベースに入れるのではなく、
用途に応じて最適なデータストアを選んでいます。

例えば、御社の在庫管理システムなら：
- 在庫の現在値 → Redis（高速更新）
- 在庫の履歴 → PostgreSQL（監査・分析）
- 商品検索 → Elasticsearch（全文検索）

というように使い分けられます。

重要なのは、複数のストアを『バラバラに管理する』のではなく、
Event-Drivenで『自動的に同期する』点です。」
```

---

## 🏗️ アーキテクチャの全体像（面接で図を描く）

### シンプル版（2分で描ける）

```
PostgreSQL ─(CDC)→ Kafka ─→ Elasticsearch
                      └─→ Redis
```

### 詳細版（5分で描ける）

```
[Write Path: 強整合性]
Client → API → PostgreSQL
                   ↓
              即座にレスポンス

[Read Path: 結果整合性]
PostgreSQL → WAL
    ↓
Debezium（CDC）
    ↓
Kafka（イベントログ）
    ↓
┌───┴───┐
↓       ↓
ES      Redis
↓       ↓
Search  Cache
```

**図を描きながら説明すべきポイント**:

1. Write PathとRead Pathの分離（CQRS）
2. 強整合性と結果整合性の境界
3. Single Source of Truth（PostgreSQL）
4. 導出データ（Elasticsearch/Redis）

---

## 💡 面接でのQ&A想定

### Q1: なぜこのプロジェクトを作ったのか？

**Good回答**:

```
「現職ではモノリシックなシステムの保守が中心で、
分散システムの設計経験がありませんでした。

御社のような中堅プロダクト企業では、
モノリス→マイクロサービス化が経営課題になると理解しています。

そこで、DDIA 12章の『解体されたデータベース』を実装し、
Event-Driven ArchitectureとPolyglot Persistenceを学びました。

特に、導出関数という抽象概念を
CDC + Kafka + 複数データストアで具体化した点が
実務でも応用できると考えています。」
```

---

### Q2: 実装で苦労した点は？

**Good回答**:

```
「結果整合性のテストが難しかったです。

PostgreSQLに書き込んだ直後は、
ElasticsearchやRedisにまだ反映されていません。

統合テストでは、最大10秒待機して
伝播を確認する仕組みを実装しました。

この経験から、分散システムでは
『最終的に整合する』という前提でテストを書く必要があると学びました。

また、伝播時間も計測しているので、
パフォーマンス劣化の早期検知もできます。」
```

---

### Q3: このプロジェクトで学んだことを、どう実務に活かせる？

**Good回答**:

```
「3つの視点で活かせます。

1. 境界設計の判断材料
   御社のモノリス分割で、
   『どこを強整合性にして、どこを結果整合性にするか』を
   導出関数の視点で判断できます。

2. 段階的な移行戦略
   CDCを使えば、既存システムを変更せずに
   新しいデータストアを追加できます。
   リスクを最小化した移行が可能です。

3. 技術選定の説得力
   『なぜElasticsearchを使うのか？』を
   導出関数という理論で説明できるので、
   ステークホルダーへの説明がしやすくなります。」
```

---

### Q4: テストはどう書いたか？

**Good回答**:

```
「単体テストと統合テストの2層構成です。

単体テストでは、DDT（Data-Driven Testing）を活用して
CREATE/UPDATE/DELETE/READの4パターンを網羅しました。

統合テストでは、実際のDockerコンテナを使って
PostgreSQL → Kafka → Elasticsearch/Redis
の全体フローをテストしています。

特に重要なのは結果整合性のテストで、
伝播時間も計測してパフォーマンス劣化を検知できます。

カバレッジ目標は80%以上に設定しており、
Consumer層の主要ロジックを網羅しています。」
```

---

## 📊 このプロジェクトの位置づけ（転職戦略）

### 職務経歴との関係

**あなたの強み**:

- ✅ 実装力（フルスタック）
- ✅ ビジネス視点（ROI意識）
- ✅ 問題発見力

**あなたの弱点**:

- ❌ モノリス→MS化の実務経験なし
- ❌ 境界設計・DDD実践の経験が浅い

**このプロジェクトの効果**:

- ✅ 弱点を「伸びしろ」に変換
- ✅ 「独学で体系的に学習している」証明
- ✅ 面接での差別化ポイント

---

### Flash Saleプロジェクトとの違い

| プロジェクト | 主眼               | 訴求ポイント             |
| ------------ | ------------------ | ------------------------ |
| Flash Sale   | DDD + 高負荷対応   | ビジネスロジックの設計力 |
| Unbundled DB | Event-Driven + CDC | 分散システムの基礎理解   |

**両方あることの強み**:

```
面接官: 「DDDとEvent-Driven、どちらも経験あるの？」
あなた: 「はい。Flash SaleでDDDを、Unbundled DBでEvent-Drivenを実装しました」
面接官: 「両方できるのは希少だな...」
```

---

## 🎯 面接で絶対に伝えるべき3つのポイント

### 1. 導出関数の概念

```
「このプロジェクトの核心は『導出関数』です。

なぜElasticsearchを使うのか？
→ 全文検索という導出関数を実行するため

なぜRedisを使うのか？
→ 高速アクセスという導出関数を実行するため

この視点があると、技術選定の説得力が増します。」
```

### 2. 結果整合性の理解

```
「分散システムでは結果整合性が避けられません。

このプロジェクトで、
強整合性（PostgreSQL）と結果整合性（Elasticsearch/Redis）を
どう使い分けるかを体験しました。

統合テストでも、伝播時間を計測する仕組みを実装しています。」
```

### 3. 実務への応用可能性

```
「この学びは、御社のモノリス→マイクロサービス移行に直結します。

特に、CDCを使った段階的な移行戦略は、
既存システムへの影響を最小化しながら
新しいアーキテクチャに移行できます。

導出関数の視点は、境界設計の判断材料になります。」
```

---

## 📝 面接前の最終チェックリスト

### 30分前に確認すること

- [ ] アーキテクチャ図を紙に描けるか？
- [ ] 導出関数を30秒で説明できるか？
- [ ] CDC/結果整合性を説明できるか？
- [ ] Flash Saleとの違いを説明できるか？
- [ ] 実務への応用例を3つ言えるか？

### 面接中に使えるフレーズ

**導入**:

- 「DDIA 12章を実装しました」
- 「導出関数という概念が核心です」
- 「CDCで段階的移行を実現しました」

**説明**:

- 「具体的には...」
- 「例えば御社の場合...」
- 「トレードオフは...」

**締め**:

- 「この学びを御社で活かしたい」
- 「実務で経験を積みたい」
- 「設計判断に貢献できます」

---

## 🚀 学習の優先順位

### 必須（絶対に理解する）

1. 解体されたデータベースの概念
2. 導出関数の考え方
3. アーキテクチャの全体像
4. 結果整合性

### 推奨（できれば理解する）

1. CDCの仕組み
2. Kafkaの役割
3. Polyglot Persistenceの利点

### オプション（詳しく聞かれたら）

1. Debeziumの設定
2. Elasticsearchのマッピング
3. Redisのデータ構造

---

**このガイドを繰り返し読んで、面接で自信を持って説明できるようになりましょう！**
